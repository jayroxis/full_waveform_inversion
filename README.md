
# Avaible Strategies For PyTorch Lightning

```bagua, colossalai, ddp, ddp_find_unused_parameters_false, ddp_fork, ddp_fork_find_unused_parameters_false, ddp_fully_sharded, ddp_notebook, ddp_notebook_find_unused_parameters_false, ddp_sharded, ddp_sharded_find_unused_parameters_false, ddp_sharded_spawn, ddp_sharded_spawn_find_unused_parameters_false, ddp_spawn, ddp_spawn_find_unused_parameters_false, deepspeed, deepspeed_stage_1, deepspeed_stage_2, deepspeed_stage_2_offload, deepspeed_stage_3, deepspeed_stage_3_offload, deepspeed_stage_3_offload_nvme, dp, fsdp, fsdp_native, fsdp_native_full_shard_offload, horovod, hpu_parallel, hpu_single, ipu_strategy, single_device, single_tpu, tpu_spawn, tpu_spawn_debug```