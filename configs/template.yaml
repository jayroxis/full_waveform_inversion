
data:
  name: Flat_Vel_A
  train_set:
    class: OpenFWIDataset
    params:
      amp_path: # your amplitude file path for training
      vel_path: # your velocity file path for training
      output_size: 256

  train_loader:
    class: torch.utils.data.DataLoader
    params:
      batch_size: 100     # effective batch size = batch_size * num_gpu
      num_workers: 8
      pin_memory: False
      shuffle: True

  val_set:
    class: OpenFWIDataset
    params:
      amp_path: # your amplitude file path for testing
      vel_path: # your velocity file path for testing
      output_size: 256

  val_loader:
    class: torch.utils.data.DataLoader
    params:
      batch_size: 100     # effective batch size = batch_size * num_gpu
      num_workers: 8
      pin_memory: False
      shuffle: False

training:
  num_epochs: 1000
  optimizer:
    class: torch.optim.AdamW
      params:
        lr: 0.0002
        weight_decay: 0.0001

  scheduler:
    class: torch.optim.lr_scheduler.CosineAnnealingLR
      params:
        T_max: 1000        # should be the same as training epochs
        eta_min: 0.0

  params:                  # arguments for PyTorch Lightning Trainer
    accelerator: gpu
    precision: 16
    strategy: ddp_find_unused_parameters_false
    enable_checkpointing: True
    check_val_every_n_epoch: 10
    log_every_n_steps: 50

model:
  name: CycleGAN
  params:
    lambda_idt: 100        # weight for identity loss (nn.L1Loss)
    lambda_gan: 1          # weight for GAN loss 
    lambda_cycle: 10       # weight for cycle-consistency loss 

  criterion:
    identity_loss: nn.L1Loss
    gan_loss: nn.BCEWithLogitsLoss
    cycle_loss: nn.L1Loss

  vel_to_amp:
    gen_config:
      class: unet           # generator model name
      params:
        in_channels: 1
        out_channels: 5
        init_features: 64
    disc_config:
      class: patch_gan_disc # discriminator model name
      params:
        input_nc: 5         # should be the same as generator out_channels
        ndf: 64
        n_layers: 3

  amp_to_vel:
    gen_config:
      class: unet
      params:
        in_channels: 5
        out_channels: 1
        init_features: 64
    disc_config:
      class: patch_gan_disc
      params:
        input_nc: 1         # should be the same as generator out_channels
        ndf: 64
        n_layers: 3

