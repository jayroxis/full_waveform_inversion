
# ====================== Data Configs =========================

data:
  name: Flat_Vel_A
  train_set:
    class: DummyFWIDataset
    params:
      output_size: 256
      num_samples: 2000

  train_loader:
    class: torch.utils.data.DataLoader
    params:
      batch_size: 20     # effective batch size = batch_size * num_gpu
      num_workers: 8
      pin_memory: False
      shuffle: True

  val_set:
    class: DummyFWIDataset
    params:
      output_size: 256

  val_loader:
    class: torch.utils.data.DataLoader
    params:
      batch_size: 100     # effective batch size = batch_size * num_gpu
      num_workers: 8
      pin_memory: False
      shuffle: False

# ==================== Training Configs =========================
training:
  num_epochs: 20
  save_dir: runs/
  optimizer:

    generator:
      class: torch.optim.AdamW
      params:
        lr: 0.0005
        weight_decay: 0.0001

    amp_disc:
      class: torch.optim.AdamW
      params:
        lr: 0.0001
        weight_decay: 0.0005

    vel_disc:
      class: torch.optim.AdamW
      params:
        lr: 0.0001
        weight_decay: 0.0005

  scheduler:
    class: torch.optim.lr_scheduler.CosineAnnealingLR
    params:
      T_max: 20            # should be the same as training epochs
      eta_min: 0.0

  params:                  # arguments for PyTorch Lightning Trainer
    accelerator: gpu
    precision: 16
    strategy: ddp
    enable_checkpointing: True
    check_val_every_n_epoch: 1
    log_every_n_steps: 50

# ====================== Model Configs =========================

model:
  name: iUNet
  class: invertible_unet
  invertible: True

  model_params:
    amp_chans: 5
    vel_chans: 1
    hidden_chans: 128
    num_layers: 3
    num_coupling_blk: 4

  train_metrics:
    mse_loss:
      class: nn.MSELoss
      weight: 1
    identity_loss: 
      class: nn.L1Loss
      weight: 1

  eval_metrics:
    identity_loss: 
      class: nn.L1Loss
    mse_loss:
      class: nn.MSELoss

