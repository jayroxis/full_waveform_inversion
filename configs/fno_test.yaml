
# ====================== Data Configs =========================

data:
  name: Flat_Vel_A
  train_set:
    class: DummyFWIDataset
    params:
      output_size: 256
      num_samples: 2000

  train_loader:
    class: torch.utils.data.DataLoader
    params:
      batch_size: 20     # effective batch size = batch_size * num_gpu
      num_workers: 8
      pin_memory: False
      shuffle: True

  val_set:
    class: DummyFWIDataset
    params:
      output_size: 256

  val_loader:
    class: torch.utils.data.DataLoader
    params:
      batch_size: 100     # effective batch size = batch_size * num_gpu
      num_workers: 8
      pin_memory: False
      shuffle: False

# ==================== Training Configs =========================
training:
  num_epochs: 20
  save_dir: runs/
  optimizer:
    class: torch.optim.AdamW
    params:
      lr: 0.001
      weight_decay: 0.0001

  scheduler:
    class: torch.optim.lr_scheduler.CosineAnnealingLR
    params:
      T_max: 20            # should be the same as training epochs
      eta_min: 0.0

  params:                  # arguments for PyTorch Lightning Trainer
    accelerator: gpu
    precision: 32          # FNO does not work for mixed-precision (16-bit)
    strategy: dp           # FNO does not work for ddp as well
    enable_checkpointing: True
    check_val_every_n_epoch: 1
    log_every_n_steps: 50

# ====================== Model Configs =========================

model:
  name: UNet

  train_metrics:
    mse_loss:
      class: nn.MSELoss
      weight: 1
    identity_loss: 
      class: nn.L1Loss
      weight: 1
  
  eval_metrics:
    identity_loss: 
      class: nn.L1Loss
    mse_loss:
      class: nn.MSELoss

  vel_to_amp:
    gen_config:
      class: fno_2d
      params:
        in_chans: 1
        out_chans: 5
        modes1: 16
        modes2: 16
        width: 64

  amp_to_vel:
    gen_config:
      class: fno_2d
      params:
        in_chans: 5
        out_chans: 1
        modes1: 16
        modes2: 16
        width: 64

