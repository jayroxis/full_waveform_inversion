
# ====================== Data Configs =========================

data:
  name: Flat_Vel_A
  train_set:
    class: DummyFWIDataset
    params:
      output_size: 256
      num_samples: 2000

  train_loader:
    class: torch.utils.data.DataLoader
    params:
      batch_size: 20     # effective batch size = batch_size * num_gpu
      num_workers: 8
      pin_memory: False
      shuffle: True

  val_set:
    class: DummyFWIDataset
    params:
      output_size: 256

  val_loader:
    class: torch.utils.data.DataLoader
    params:
      batch_size: 100     # effective batch size = batch_size * num_gpu
      num_workers: 8
      pin_memory: False
      shuffle: False

# ==================== Training Configs =========================
training:
  num_epochs: 20
  save_dir: runs/
  optimizer:

    generator:
      class: torch.optim.AdamW
      params:
        lr: 0.0005
        weight_decay: 0.0001

    amp_disc:
      class: torch.optim.AdamW
      params:
        lr: 0.0001
        weight_decay: 0.0005

    vel_disc:
      class: torch.optim.AdamW
      params:
        lr: 0.0001
        weight_decay: 0.0005

  scheduler:
    class: torch.optim.lr_scheduler.CosineAnnealingLR
    params:
      T_max: 20            # should be the same as training epochs
      eta_min: 0.0

  params:                  # arguments for PyTorch Lightning Trainer
    accelerator: gpu
    precision: 16
    strategy: ddp
    enable_checkpointing: True
    check_val_every_n_epoch: 1
    log_every_n_steps: 50

# ====================== Model Configs =========================

model:
  name: Pix2Pix

  train_metrics:
    mse_loss:
      class: nn.MSELoss
      weight: 100
    identity_loss: 
      class: nn.L1Loss
      weight: 100
    gan_loss:
      class: nn.BCEWithLogitsLoss
      weight: 1
  
  eval_metrics:
    identity_loss: 
      class: nn.L1Loss
    mse_loss:
      class: nn.MSELoss

  vel_to_amp:
    gen_config:
      class: unet           # generator model name
      params:
        in_channels: 1
        out_channels: 5
        init_features: 32

    disc_config:
      class: patch_gan_disc # discriminator model name
      params:
        input_nc: 5         # should be the same as generator out_channels
        ndf: 64
        n_layers: 3

  amp_to_vel:
    gen_config:
      class: unet
      params:
        in_channels: 5
        out_channels: 1
        init_features: 32

    disc_config:
      class: patch_gan_disc
      params:
        input_nc: 1         # should be the same as generator out_channels
        ndf: 64
        n_layers: 3

